


from bs4 import BeautifulSoup


def parse_html_urls(html):
    soup = BeautifulSoup(html, 'html.parser')
    
    # get all links
    for link in soup.find_all('a'):
        url = link.get('href')
        if url:
            yield url
    # get all form actions
    for form in soup.find_all('form'):
        url = form.get('action')
        if url:
            yield url


def get_page_urls(html: str):
    # Extract all urls from an HTML page using BeautifulSoup
    soup = BeautifulSoup(html, 'html.parser')
    urls = []
    for link in soup.find_all('a'):
        url = link.get('href')
        if url:
            urls.append(url)
    return urls